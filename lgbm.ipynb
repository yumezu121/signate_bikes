{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "#import optuna.integration.lightgbm as lgb\n",
    "from datetime import date,timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yumezu/anaconda3/envs/kaggle/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "whole = pd.read_csv('whole.csv')\n",
    "whole = whole.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole['date'] = pd.to_datetime(whole['date'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list(whole[whole['predict'] == 1]['date'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s = ls[0]\n",
    "\n",
    "train = whole[whole['date'] < s]\n",
    "train = train.append(train[train['date'] == s][train['hour'] == 0])\n",
    "test = whole[whole['date'] == s][whole['predict'] == 1]\n",
    "\n",
    "x = train.drop(['id', 'year', 'predict', 'date', 'events', 'bikes_available'], axis=1)\n",
    "y = train['bikes_available']\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits=100)\n",
    "\n",
    "for tr_idx, va_idx in tss.split(train):\n",
    "    tr_x, va_x = x.iloc[tr_idx], x.iloc[va_idx]\n",
    "    tr_y, va_y = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "lgb_train = lgb.Dataset(tr_x,tr_y)\n",
    "lgb_eval = lgb.Dataset(va_x,va_y)\n",
    "\n",
    "params = {\n",
    "    'objective':'regression',\n",
    "    'metric':'rmse',\n",
    "}\n",
    "\n",
    "model = lgb.train(params,lgb_train,valid_sets=[lgb_train,lgb_eval],\n",
    "                early_stopping_rounds=100,\n",
    "                verbose_eval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.params\n",
    "\n",
    "{'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'feature_pre_filter': False,\n",
    "                'lambda_l1': 3.0219157234596604e-06,\n",
    "                'lambda_l2': 2.6309832619595715e-05,\n",
    "                'num_leaves': 137,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 1.0,\n",
    "                'bagging_freq': 0,\n",
    "                'min_child_samples': 5,\n",
    "                'num_iterations': 1000,\n",
    "                'early_stopping_round': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################\n",
      "1/120\n",
      "############################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_284696/2876090964.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  train = train.append(whole[whole['date'] == s][whole['hour'] == 0])\n",
      "/tmp/ipykernel_284696/2876090964.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  test = whole[whole['date'] == s][whole['predict'] == 1]\n",
      "/tmp/ipykernel_284696/2876090964.py:36: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  test = whole[whole['date'] == s][whole['predict'] == 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN_train 0\n",
      "NaN_test 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yumezu/anaconda3/envs/kaggle/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/yumezu/anaconda3/envs/kaggle/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/yumezu/anaconda3/envs/kaggle/lib/python3.8/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 539424, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.602239\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51461\tvalid_1's rmse: 3.18134\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's rmse: 2.70729\tvalid_1's rmse: 3.16479\n",
      "############################################\n",
      "2/120\n",
      "############################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_284696/2876090964.py:114: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  train = train.append(whole[whole['date'] == s][whole['hour'] == 0])\n",
      "/tmp/ipykernel_284696/2876090964.py:115: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  test = whole[whole['date'] == s][whole['predict'] == 1]\n",
      "/tmp/ipykernel_284696/2876090964.py:139: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  test = whole[whole['date'] == s][whole['predict'] == 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1100\n",
      "[LightGBM] [Info] Number of data points in the train set: 544464, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.602018\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52864\tvalid_1's rmse: 3.12468\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's rmse: 2.62704\tvalid_1's rmse: 3.12175\n",
      "############################################\n",
      "3/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1100\n",
      "[LightGBM] [Info] Number of data points in the train set: 547824, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.601538\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52173\tvalid_1's rmse: 3.11002\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's rmse: 2.63366\tvalid_1's rmse: 3.09552\n",
      "############################################\n",
      "4/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 554544, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.599271\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52291\tvalid_1's rmse: 3.04479\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's rmse: 2.66409\tvalid_1's rmse: 3.03544\n",
      "############################################\n",
      "5/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 567984, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.591062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.53529\tvalid_1's rmse: 3.00538\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's rmse: 2.66001\tvalid_1's rmse: 3.00161\n",
      "############################################\n",
      "6/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1103\n",
      "[LightGBM] [Info] Number of data points in the train set: 571344, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.590047\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.53914\tvalid_1's rmse: 2.99389\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's rmse: 2.66577\tvalid_1's rmse: 2.98599\n",
      "############################################\n",
      "7/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1104\n",
      "[LightGBM] [Info] Number of data points in the train set: 574704, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.588759\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.5433\tvalid_1's rmse: 2.94615\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's rmse: 2.72558\tvalid_1's rmse: 2.93261\n",
      "############################################\n",
      "8/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1105\n",
      "[LightGBM] [Info] Number of data points in the train set: 579744, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.586673\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.54359\tvalid_1's rmse: 2.89177\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's rmse: 2.71349\tvalid_1's rmse: 2.88543\n",
      "############################################\n",
      "9/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1105\n",
      "[LightGBM] [Info] Number of data points in the train set: 583104, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.584254\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55718\tvalid_1's rmse: 2.85287\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's rmse: 2.67991\tvalid_1's rmse: 2.84601\n",
      "############################################\n",
      "10/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1105\n",
      "[LightGBM] [Info] Number of data points in the train set: 586464, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.582760\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55118\tvalid_1's rmse: 2.78562\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's rmse: 2.71122\tvalid_1's rmse: 2.77531\n",
      "############################################\n",
      "11/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1105\n",
      "[LightGBM] [Info] Number of data points in the train set: 593184, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.580693\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55807\tvalid_1's rmse: 2.81295\n",
      "[200]\ttraining's rmse: 2.35847\tvalid_1's rmse: 2.8207\n",
      "Early stopping, best iteration is:\n",
      "[131]\ttraining's rmse: 2.49136\tvalid_1's rmse: 2.81123\n",
      "############################################\n",
      "12/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1109\n",
      "[LightGBM] [Info] Number of data points in the train set: 599904, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.578193\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55771\tvalid_1's rmse: 2.76561\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's rmse: 2.60376\tvalid_1's rmse: 2.76259\n",
      "############################################\n",
      "13/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1109\n",
      "[LightGBM] [Info] Number of data points in the train set: 603264, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.577529\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55089\tvalid_1's rmse: 2.78639\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's rmse: 2.57236\tvalid_1's rmse: 2.78305\n",
      "############################################\n",
      "14/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1109\n",
      "[LightGBM] [Info] Number of data points in the train set: 606624, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.575561\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55161\tvalid_1's rmse: 2.6487\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's rmse: 2.59004\tvalid_1's rmse: 2.64338\n",
      "############################################\n",
      "15/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1109\n",
      "[LightGBM] [Info] Number of data points in the train set: 618384, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.570042\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.5535\tvalid_1's rmse: 2.84424\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's rmse: 2.63296\tvalid_1's rmse: 2.83959\n",
      "############################################\n",
      "16/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1111\n",
      "[LightGBM] [Info] Number of data points in the train set: 621744, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.568671\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55706\tvalid_1's rmse: 2.82403\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's rmse: 2.62811\tvalid_1's rmse: 2.81677\n",
      "############################################\n",
      "17/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1111\n",
      "[LightGBM] [Info] Number of data points in the train set: 625104, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.568088\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56821\tvalid_1's rmse: 2.82289\n",
      "[200]\ttraining's rmse: 2.36809\tvalid_1's rmse: 2.82827\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttraining's rmse: 2.49949\tvalid_1's rmse: 2.82015\n",
      "############################################\n",
      "18/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1111\n",
      "[LightGBM] [Info] Number of data points in the train set: 630144, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.566293\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56017\tvalid_1's rmse: 2.8951\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's rmse: 2.63687\tvalid_1's rmse: 2.89057\n",
      "############################################\n",
      "19/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1113\n",
      "[LightGBM] [Info] Number of data points in the train set: 633504, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.566412\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55878\tvalid_1's rmse: 2.8774\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's rmse: 2.73685\tvalid_1's rmse: 2.87053\n",
      "############################################\n",
      "20/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1114\n",
      "[LightGBM] [Info] Number of data points in the train set: 636864, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.565859\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56239\tvalid_1's rmse: 2.89802\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's rmse: 2.73998\tvalid_1's rmse: 2.89143\n",
      "############################################\n",
      "21/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1115\n",
      "[LightGBM] [Info] Number of data points in the train set: 641904, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.563527\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55982\tvalid_1's rmse: 2.92735\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's rmse: 2.59096\tvalid_1's rmse: 2.92544\n",
      "############################################\n",
      "22/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1116\n",
      "[LightGBM] [Info] Number of data points in the train set: 645264, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.562514\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56014\tvalid_1's rmse: 2.82166\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's rmse: 2.60073\tvalid_1's rmse: 2.81833\n",
      "############################################\n",
      "23/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1120\n",
      "[LightGBM] [Info] Number of data points in the train set: 648624, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.562397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.54573\tvalid_1's rmse: 2.93208\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's rmse: 2.6823\tvalid_1's rmse: 2.92373\n",
      "############################################\n",
      "24/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1120\n",
      "[LightGBM] [Info] Number of data points in the train set: 651984, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.561329\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56013\tvalid_1's rmse: 2.87333\n",
      "[200]\ttraining's rmse: 2.37894\tvalid_1's rmse: 2.87588\n",
      "Early stopping, best iteration is:\n",
      "[118]\ttraining's rmse: 2.52149\tvalid_1's rmse: 2.86857\n",
      "############################################\n",
      "25/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 663744, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.559634\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.5567\tvalid_1's rmse: 2.95402\n",
      "[200]\ttraining's rmse: 2.35686\tvalid_1's rmse: 2.9556\n",
      "Early stopping, best iteration is:\n",
      "[185]\ttraining's rmse: 2.38235\tvalid_1's rmse: 2.95322\n",
      "############################################\n",
      "26/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1125\n",
      "[LightGBM] [Info] Number of data points in the train set: 670464, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.555515\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56465\tvalid_1's rmse: 2.7013\n",
      "[200]\ttraining's rmse: 2.37002\tvalid_1's rmse: 2.69803\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's rmse: 2.44086\tvalid_1's rmse: 2.69367\n",
      "############################################\n",
      "27/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1126\n",
      "[LightGBM] [Info] Number of data points in the train set: 673824, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.555234\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56298\tvalid_1's rmse: 2.6895\n",
      "[200]\ttraining's rmse: 2.37337\tvalid_1's rmse: 2.67827\n",
      "[300]\ttraining's rmse: 2.23373\tvalid_1's rmse: 2.6838\n",
      "Early stopping, best iteration is:\n",
      "[207]\ttraining's rmse: 2.36059\tvalid_1's rmse: 2.67607\n",
      "############################################\n",
      "28/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1128\n",
      "[LightGBM] [Info] Number of data points in the train set: 677184, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.554239\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55941\tvalid_1's rmse: 2.60442\n",
      "[200]\ttraining's rmse: 2.37884\tvalid_1's rmse: 2.60429\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's rmse: 2.46095\tvalid_1's rmse: 2.59863\n",
      "############################################\n",
      "29/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1128\n",
      "[LightGBM] [Info] Number of data points in the train set: 680544, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.552898\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56703\tvalid_1's rmse: 2.57272\n",
      "[200]\ttraining's rmse: 2.3832\tvalid_1's rmse: 2.57407\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttraining's rmse: 2.44633\tvalid_1's rmse: 2.56867\n",
      "############################################\n",
      "30/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 688944, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.552146\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56805\tvalid_1's rmse: 2.64467\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's rmse: 2.68673\tvalid_1's rmse: 2.63938\n",
      "############################################\n",
      "31/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 693984, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.551865\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56114\tvalid_1's rmse: 2.61384\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's rmse: 2.67634\tvalid_1's rmse: 2.59921\n",
      "############################################\n",
      "32/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1135\n",
      "[LightGBM] [Info] Number of data points in the train set: 702384, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.552094\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56626\tvalid_1's rmse: 2.7906\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's rmse: 2.67958\tvalid_1's rmse: 2.77933\n",
      "############################################\n",
      "33/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1137\n",
      "[LightGBM] [Info] Number of data points in the train set: 705744, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.551531\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56446\tvalid_1's rmse: 2.78416\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's rmse: 2.72982\tvalid_1's rmse: 2.77582\n",
      "############################################\n",
      "34/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1137\n",
      "[LightGBM] [Info] Number of data points in the train set: 710784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.550657\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56009\tvalid_1's rmse: 2.81335\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's rmse: 2.6867\tvalid_1's rmse: 2.8017\n",
      "############################################\n",
      "35/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1137\n",
      "[LightGBM] [Info] Number of data points in the train set: 714144, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.549366\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56382\tvalid_1's rmse: 2.78093\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's rmse: 2.68927\tvalid_1's rmse: 2.77337\n",
      "############################################\n",
      "36/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1139\n",
      "[LightGBM] [Info] Number of data points in the train set: 720864, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.550031\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56031\tvalid_1's rmse: 2.82069\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's rmse: 2.66354\tvalid_1's rmse: 2.81839\n",
      "############################################\n",
      "37/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.093682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1139\n",
      "[LightGBM] [Info] Number of data points in the train set: 724224, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.549822\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55758\tvalid_1's rmse: 2.75674\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's rmse: 2.66003\tvalid_1's rmse: 2.74947\n",
      "############################################\n",
      "38/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.094310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 730944, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.549805\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55145\tvalid_1's rmse: 2.87989\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's rmse: 2.68951\tvalid_1's rmse: 2.85578\n",
      "############################################\n",
      "39/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1150\n",
      "[LightGBM] [Info] Number of data points in the train set: 737664, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.549589\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55458\tvalid_1's rmse: 2.85727\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's rmse: 2.69052\tvalid_1's rmse: 2.84806\n",
      "############################################\n",
      "40/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1151\n",
      "[LightGBM] [Info] Number of data points in the train set: 741024, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.550003\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55695\tvalid_1's rmse: 2.78457\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's rmse: 2.70026\tvalid_1's rmse: 2.76993\n",
      "############################################\n",
      "41/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1155\n",
      "[LightGBM] [Info] Number of data points in the train set: 746064, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.549824\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.56217\tvalid_1's rmse: 2.67324\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's rmse: 2.69037\tvalid_1's rmse: 2.67173\n",
      "############################################\n",
      "42/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1162\n",
      "[LightGBM] [Info] Number of data points in the train set: 749424, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.549624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.5571\tvalid_1's rmse: 2.67152\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's rmse: 2.66068\tvalid_1's rmse: 2.65932\n",
      "############################################\n",
      "43/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1165\n",
      "[LightGBM] [Info] Number of data points in the train set: 752784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.550105\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55975\tvalid_1's rmse: 2.5945\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's rmse: 2.69752\tvalid_1's rmse: 2.57893\n",
      "############################################\n",
      "44/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.106480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1166\n",
      "[LightGBM] [Info] Number of data points in the train set: 756144, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.550981\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.54564\tvalid_1's rmse: 2.49979\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's rmse: 2.60876\tvalid_1's rmse: 2.49207\n",
      "############################################\n",
      "45/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1166\n",
      "[LightGBM] [Info] Number of data points in the train set: 759504, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.550535\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55076\tvalid_1's rmse: 2.43848\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's rmse: 2.65386\tvalid_1's rmse: 2.43106\n",
      "############################################\n",
      "46/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1175\n",
      "[LightGBM] [Info] Number of data points in the train set: 766224, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.551103\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.5557\tvalid_1's rmse: 2.39755\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's rmse: 2.78219\tvalid_1's rmse: 2.37762\n",
      "############################################\n",
      "47/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1178\n",
      "[LightGBM] [Info] Number of data points in the train set: 769584, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.550981\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55643\tvalid_1's rmse: 2.3389\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's rmse: 2.74711\tvalid_1's rmse: 2.31178\n",
      "############################################\n",
      "48/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1184\n",
      "[LightGBM] [Info] Number of data points in the train set: 783024, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.552118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.54345\tvalid_1's rmse: 2.4548\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's rmse: 2.78071\tvalid_1's rmse: 2.43362\n",
      "############################################\n",
      "49/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1184\n",
      "[LightGBM] [Info] Number of data points in the train set: 786384, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.552038\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55189\tvalid_1's rmse: 2.49001\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's rmse: 2.71289\tvalid_1's rmse: 2.47213\n",
      "############################################\n",
      "50/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1186\n",
      "[LightGBM] [Info] Number of data points in the train set: 793104, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.552662\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55981\tvalid_1's rmse: 2.48016\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's rmse: 2.73931\tvalid_1's rmse: 2.46263\n",
      "############################################\n",
      "51/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1196\n",
      "[LightGBM] [Info] Number of data points in the train set: 799824, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.552224\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.55433\tvalid_1's rmse: 2.58016\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's rmse: 2.68072\tvalid_1's rmse: 2.56662\n",
      "############################################\n",
      "52/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1197\n",
      "[LightGBM] [Info] Number of data points in the train set: 803184, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.552131\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.54591\tvalid_1's rmse: 2.55683\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's rmse: 2.70974\tvalid_1's rmse: 2.54691\n",
      "############################################\n",
      "53/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1199\n",
      "[LightGBM] [Info] Number of data points in the train set: 809904, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.552328\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.54911\tvalid_1's rmse: 2.62625\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's rmse: 2.73733\tvalid_1's rmse: 2.6123\n",
      "############################################\n",
      "54/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 816624, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.551479\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.54013\tvalid_1's rmse: 2.6693\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's rmse: 2.6543\tvalid_1's rmse: 2.66056\n",
      "############################################\n",
      "55/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 819984, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.550434\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.54362\tvalid_1's rmse: 2.648\n",
      "[200]\ttraining's rmse: 2.36767\tvalid_1's rmse: 2.65333\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's rmse: 2.4777\tvalid_1's rmse: 2.64372\n",
      "############################################\n",
      "56/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 823344, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.550665\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.528\tvalid_1's rmse: 2.63928\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's rmse: 2.55014\tvalid_1's rmse: 2.63639\n",
      "############################################\n",
      "57/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 828384, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.549412\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.53654\tvalid_1's rmse: 2.65377\n",
      "[200]\ttraining's rmse: 2.37489\tvalid_1's rmse: 2.65034\n",
      "Early stopping, best iteration is:\n",
      "[185]\ttraining's rmse: 2.39773\tvalid_1's rmse: 2.64891\n",
      "############################################\n",
      "58/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 831744, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.547504\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.53119\tvalid_1's rmse: 2.58877\n",
      "[200]\ttraining's rmse: 2.35381\tvalid_1's rmse: 2.58305\n",
      "[300]\ttraining's rmse: 2.22794\tvalid_1's rmse: 2.58522\n",
      "Early stopping, best iteration is:\n",
      "[224]\ttraining's rmse: 2.32071\tvalid_1's rmse: 2.57646\n",
      "############################################\n",
      "59/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1201\n",
      "[LightGBM] [Info] Number of data points in the train set: 836784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.546058\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.53906\tvalid_1's rmse: 2.52668\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's rmse: 2.6197\tvalid_1's rmse: 2.52497\n",
      "############################################\n",
      "60/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1201\n",
      "[LightGBM] [Info] Number of data points in the train set: 840144, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.545373\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.53996\tvalid_1's rmse: 2.55331\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's rmse: 2.54811\tvalid_1's rmse: 2.55312\n",
      "############################################\n",
      "61/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1202\n",
      "[LightGBM] [Info] Number of data points in the train set: 843504, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.542831\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.54056\tvalid_1's rmse: 2.50884\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's rmse: 2.67935\tvalid_1's rmse: 2.50002\n",
      "############################################\n",
      "62/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1202\n",
      "[LightGBM] [Info] Number of data points in the train set: 846864, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.541917\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.54451\tvalid_1's rmse: 2.41889\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's rmse: 2.59397\tvalid_1's rmse: 2.41524\n",
      "############################################\n",
      "63/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1203\n",
      "[LightGBM] [Info] Number of data points in the train set: 855264, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.539372\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.53992\tvalid_1's rmse: 2.4727\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's rmse: 2.63493\tvalid_1's rmse: 2.46547\n",
      "############################################\n",
      "64/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1206\n",
      "[LightGBM] [Info] Number of data points in the train set: 858624, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.539423\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.53016\tvalid_1's rmse: 2.48948\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's rmse: 2.67781\tvalid_1's rmse: 2.48287\n",
      "############################################\n",
      "65/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1209\n",
      "[LightGBM] [Info] Number of data points in the train set: 863664, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.539022\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52939\tvalid_1's rmse: 2.42496\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's rmse: 2.6163\tvalid_1's rmse: 2.42322\n",
      "############################################\n",
      "66/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.110464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1209\n",
      "[LightGBM] [Info] Number of data points in the train set: 867024, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.538064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52561\tvalid_1's rmse: 2.46113\n",
      "[200]\ttraining's rmse: 2.36105\tvalid_1's rmse: 2.47039\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's rmse: 2.4773\tvalid_1's rmse: 2.45792\n",
      "############################################\n",
      "67/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1209\n",
      "[LightGBM] [Info] Number of data points in the train set: 870384, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.537335\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.53504\tvalid_1's rmse: 2.38315\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's rmse: 2.62942\tvalid_1's rmse: 2.37723\n",
      "############################################\n",
      "68/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1209\n",
      "[LightGBM] [Info] Number of data points in the train set: 875424, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.537534\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.53274\tvalid_1's rmse: 2.40018\n",
      "[200]\ttraining's rmse: 2.35615\tvalid_1's rmse: 2.41089\n",
      "Early stopping, best iteration is:\n",
      "[126]\ttraining's rmse: 2.4765\tvalid_1's rmse: 2.39788\n",
      "############################################\n",
      "69/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1209\n",
      "[LightGBM] [Info] Number of data points in the train set: 880464, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.534736\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.53425\tvalid_1's rmse: 2.43848\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's rmse: 2.66154\tvalid_1's rmse: 2.43393\n",
      "############################################\n",
      "70/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1210\n",
      "[LightGBM] [Info] Number of data points in the train set: 885504, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.534339\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.53802\tvalid_1's rmse: 2.4271\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's rmse: 2.56525\tvalid_1's rmse: 2.42536\n",
      "############################################\n",
      "71/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.110674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1213\n",
      "[LightGBM] [Info] Number of data points in the train set: 895584, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.531055\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.53519\tvalid_1's rmse: 2.51098\n",
      "[200]\ttraining's rmse: 2.36328\tvalid_1's rmse: 2.51614\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's rmse: 2.49055\tvalid_1's rmse: 2.50144\n",
      "############################################\n",
      "72/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1214\n",
      "[LightGBM] [Info] Number of data points in the train set: 900624, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.531058\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52435\tvalid_1's rmse: 2.59165\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's rmse: 2.58988\tvalid_1's rmse: 2.5895\n",
      "############################################\n",
      "73/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1215\n",
      "[LightGBM] [Info] Number of data points in the train set: 903984, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.529897\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52581\tvalid_1's rmse: 2.54172\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's rmse: 2.57219\tvalid_1's rmse: 2.53295\n",
      "############################################\n",
      "74/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1215\n",
      "[LightGBM] [Info] Number of data points in the train set: 914064, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.529097\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52195\tvalid_1's rmse: 2.6971\n",
      "[200]\ttraining's rmse: 2.35972\tvalid_1's rmse: 2.68218\n",
      "Early stopping, best iteration is:\n",
      "[199]\ttraining's rmse: 2.36117\tvalid_1's rmse: 2.68131\n",
      "############################################\n",
      "75/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1215\n",
      "[LightGBM] [Info] Number of data points in the train set: 917424, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.527917\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51977\tvalid_1's rmse: 2.59634\n",
      "[200]\ttraining's rmse: 2.35401\tvalid_1's rmse: 2.58438\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's rmse: 2.42669\tvalid_1's rmse: 2.58132\n",
      "############################################\n",
      "76/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1216\n",
      "[LightGBM] [Info] Number of data points in the train set: 924144, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.527430\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51492\tvalid_1's rmse: 2.69098\n",
      "[200]\ttraining's rmse: 2.35922\tvalid_1's rmse: 2.68419\n",
      "[300]\ttraining's rmse: 2.24846\tvalid_1's rmse: 2.6922\n",
      "Early stopping, best iteration is:\n",
      "[200]\ttraining's rmse: 2.35922\tvalid_1's rmse: 2.68419\n",
      "############################################\n",
      "77/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1216\n",
      "[LightGBM] [Info] Number of data points in the train set: 927504, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.526255\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51946\tvalid_1's rmse: 2.60397\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's rmse: 2.52104\tvalid_1's rmse: 2.60387\n",
      "############################################\n",
      "78/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1216\n",
      "[LightGBM] [Info] Number of data points in the train set: 930864, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.526170\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52044\tvalid_1's rmse: 2.50979\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's rmse: 2.58117\tvalid_1's rmse: 2.50705\n",
      "############################################\n",
      "79/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1217\n",
      "[LightGBM] [Info] Number of data points in the train set: 934224, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.525905\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51656\tvalid_1's rmse: 2.502\n",
      "[200]\ttraining's rmse: 2.35222\tvalid_1's rmse: 2.50616\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's rmse: 2.50859\tvalid_1's rmse: 2.50174\n",
      "############################################\n",
      "80/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1217\n",
      "[LightGBM] [Info] Number of data points in the train set: 939264, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.524564\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51512\tvalid_1's rmse: 2.50643\n",
      "[200]\ttraining's rmse: 2.34948\tvalid_1's rmse: 2.50939\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's rmse: 2.44386\tvalid_1's rmse: 2.50223\n",
      "############################################\n",
      "81/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1217\n",
      "[LightGBM] [Info] Number of data points in the train set: 947664, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.518797\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51853\tvalid_1's rmse: 2.41368\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's rmse: 2.56597\tvalid_1's rmse: 2.40991\n",
      "############################################\n",
      "82/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.116167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1218\n",
      "[LightGBM] [Info] Number of data points in the train set: 952704, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.517559\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52292\tvalid_1's rmse: 2.47462\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's rmse: 2.55618\tvalid_1's rmse: 2.47352\n",
      "############################################\n",
      "83/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.116135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1219\n",
      "[LightGBM] [Info] Number of data points in the train set: 956064, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.516286\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.50904\tvalid_1's rmse: 2.45871\n",
      "[200]\ttraining's rmse: 2.35989\tvalid_1's rmse: 2.45508\n",
      "Early stopping, best iteration is:\n",
      "[160]\ttraining's rmse: 2.41182\tvalid_1's rmse: 2.45105\n",
      "############################################\n",
      "84/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.117968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1221\n",
      "[LightGBM] [Info] Number of data points in the train set: 959424, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.514531\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51616\tvalid_1's rmse: 2.44155\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's rmse: 2.56449\tvalid_1's rmse: 2.43943\n",
      "############################################\n",
      "85/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.117761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1221\n",
      "[LightGBM] [Info] Number of data points in the train set: 967824, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.511522\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51905\tvalid_1's rmse: 2.48146\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's rmse: 2.59187\tvalid_1's rmse: 2.47419\n",
      "############################################\n",
      "86/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.118603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1221\n",
      "[LightGBM] [Info] Number of data points in the train set: 971184, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.511243\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51803\tvalid_1's rmse: 2.55351\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's rmse: 2.5856\tvalid_1's rmse: 2.54872\n",
      "############################################\n",
      "87/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.120275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1221\n",
      "[LightGBM] [Info] Number of data points in the train set: 979584, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.509314\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51713\tvalid_1's rmse: 2.64526\n",
      "[200]\ttraining's rmse: 2.3647\tvalid_1's rmse: 2.64728\n",
      "Early stopping, best iteration is:\n",
      "[147]\ttraining's rmse: 2.4387\tvalid_1's rmse: 2.64361\n",
      "############################################\n",
      "88/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.119739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1222\n",
      "[LightGBM] [Info] Number of data points in the train set: 982944, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.509166\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51115\tvalid_1's rmse: 2.715\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's rmse: 2.58622\tvalid_1's rmse: 2.71023\n",
      "############################################\n",
      "89/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.120054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1223\n",
      "[LightGBM] [Info] Number of data points in the train set: 986304, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.508496\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51604\tvalid_1's rmse: 2.6905\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's rmse: 2.52486\tvalid_1's rmse: 2.68959\n",
      "############################################\n",
      "90/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1223\n",
      "[LightGBM] [Info] Number of data points in the train set: 989664, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.508648\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51502\tvalid_1's rmse: 2.77778\n",
      "[200]\ttraining's rmse: 2.36463\tvalid_1's rmse: 2.77593\n",
      "Early stopping, best iteration is:\n",
      "[195]\ttraining's rmse: 2.37236\tvalid_1's rmse: 2.77519\n",
      "############################################\n",
      "91/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1224\n",
      "[LightGBM] [Info] Number of data points in the train set: 1001424, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.507048\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.50275\tvalid_1's rmse: 2.89294\n",
      "[200]\ttraining's rmse: 2.35126\tvalid_1's rmse: 2.89027\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's rmse: 2.41407\tvalid_1's rmse: 2.888\n",
      "############################################\n",
      "92/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1225\n",
      "[LightGBM] [Info] Number of data points in the train set: 1004784, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.505834\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51436\tvalid_1's rmse: 2.7536\n",
      "[200]\ttraining's rmse: 2.36276\tvalid_1's rmse: 2.74782\n",
      "[300]\ttraining's rmse: 2.24229\tvalid_1's rmse: 2.74223\n",
      "Early stopping, best iteration is:\n",
      "[244]\ttraining's rmse: 2.30483\tvalid_1's rmse: 2.73643\n",
      "############################################\n",
      "93/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1226\n",
      "[LightGBM] [Info] Number of data points in the train set: 1009824, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.505450\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51017\tvalid_1's rmse: 2.8503\n",
      "[200]\ttraining's rmse: 2.35392\tvalid_1's rmse: 2.85352\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's rmse: 2.47363\tvalid_1's rmse: 2.84885\n",
      "############################################\n",
      "94/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1226\n",
      "[LightGBM] [Info] Number of data points in the train set: 1016544, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.503507\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51365\tvalid_1's rmse: 2.81027\n",
      "[200]\ttraining's rmse: 2.36496\tvalid_1's rmse: 2.81259\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttraining's rmse: 2.43996\tvalid_1's rmse: 2.80769\n",
      "############################################\n",
      "95/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1229\n",
      "[LightGBM] [Info] Number of data points in the train set: 1021584, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.500498\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.50869\tvalid_1's rmse: 2.81824\n",
      "[200]\ttraining's rmse: 2.35057\tvalid_1's rmse: 2.81816\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's rmse: 2.4172\tvalid_1's rmse: 2.81404\n",
      "############################################\n",
      "96/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1229\n",
      "[LightGBM] [Info] Number of data points in the train set: 1026624, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.499872\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.50905\tvalid_1's rmse: 2.84832\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's rmse: 2.57223\tvalid_1's rmse: 2.8397\n",
      "############################################\n",
      "97/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1229\n",
      "[LightGBM] [Info] Number of data points in the train set: 1029984, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.497626\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51816\tvalid_1's rmse: 2.68952\n",
      "[200]\ttraining's rmse: 2.36408\tvalid_1's rmse: 2.7007\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's rmse: 2.50926\tvalid_1's rmse: 2.68728\n",
      "############################################\n",
      "98/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1230\n",
      "[LightGBM] [Info] Number of data points in the train set: 1036704, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.495994\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51304\tvalid_1's rmse: 2.76373\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's rmse: 2.62601\tvalid_1's rmse: 2.75751\n",
      "############################################\n",
      "99/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1230\n",
      "[LightGBM] [Info] Number of data points in the train set: 1040064, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.495451\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51216\tvalid_1's rmse: 2.74107\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's rmse: 2.67393\tvalid_1's rmse: 2.70163\n",
      "############################################\n",
      "100/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1230\n",
      "[LightGBM] [Info] Number of data points in the train set: 1045104, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.493795\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51157\tvalid_1's rmse: 2.75147\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's rmse: 2.67522\tvalid_1's rmse: 2.74154\n",
      "############################################\n",
      "101/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1230\n",
      "[LightGBM] [Info] Number of data points in the train set: 1050144, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.491853\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51406\tvalid_1's rmse: 2.67504\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's rmse: 2.64294\tvalid_1's rmse: 2.66302\n",
      "############################################\n",
      "102/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1231\n",
      "[LightGBM] [Info] Number of data points in the train set: 1053504, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.489358\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51651\tvalid_1's rmse: 2.52957\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's rmse: 2.61033\tvalid_1's rmse: 2.51095\n",
      "############################################\n",
      "103/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1231\n",
      "[LightGBM] [Info] Number of data points in the train set: 1060224, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.487758\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.50943\tvalid_1's rmse: 2.68862\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's rmse: 2.65656\tvalid_1's rmse: 2.65794\n",
      "############################################\n",
      "104/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1231\n",
      "[LightGBM] [Info] Number of data points in the train set: 1063584, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.486873\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51484\tvalid_1's rmse: 2.60907\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's rmse: 2.61696\tvalid_1's rmse: 2.58865\n",
      "############################################\n",
      "105/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.131496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1232\n",
      "[LightGBM] [Info] Number of data points in the train set: 1068624, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.485049\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51674\tvalid_1's rmse: 2.47311\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's rmse: 2.63562\tvalid_1's rmse: 2.45646\n",
      "############################################\n",
      "106/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1233\n",
      "[LightGBM] [Info] Number of data points in the train set: 1071984, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.483915\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51766\tvalid_1's rmse: 2.45711\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's rmse: 2.65021\tvalid_1's rmse: 2.43787\n",
      "############################################\n",
      "107/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1075344, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.483153\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52406\tvalid_1's rmse: 2.39154\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's rmse: 2.6797\tvalid_1's rmse: 2.3741\n",
      "############################################\n",
      "108/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1082064, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.479840\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52343\tvalid_1's rmse: 2.39083\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's rmse: 2.72115\tvalid_1's rmse: 2.34933\n",
      "############################################\n",
      "109/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.132176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1090464, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.477119\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51749\tvalid_1's rmse: 2.35846\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's rmse: 2.71949\tvalid_1's rmse: 2.33404\n",
      "############################################\n",
      "110/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.133182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1097184, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.475184\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51087\tvalid_1's rmse: 2.38954\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's rmse: 2.71268\tvalid_1's rmse: 2.35901\n",
      "############################################\n",
      "111/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1100544, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.473823\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51778\tvalid_1's rmse: 2.35237\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's rmse: 2.65462\tvalid_1's rmse: 2.33186\n",
      "############################################\n",
      "112/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1103904, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.472779\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52192\tvalid_1's rmse: 2.2604\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's rmse: 2.65964\tvalid_1's rmse: 2.24093\n",
      "############################################\n",
      "113/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1108944, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.471040\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51857\tvalid_1's rmse: 2.2837\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's rmse: 2.64348\tvalid_1's rmse: 2.25421\n",
      "############################################\n",
      "114/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1112304, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.469917\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.52178\tvalid_1's rmse: 2.19464\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's rmse: 2.65658\tvalid_1's rmse: 2.18051\n",
      "############################################\n",
      "115/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.137857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1115664, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.468844\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51614\tvalid_1's rmse: 2.20469\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's rmse: 2.67845\tvalid_1's rmse: 2.18715\n",
      "############################################\n",
      "116/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1122384, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.466400\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51302\tvalid_1's rmse: 2.3459\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's rmse: 2.67927\tvalid_1's rmse: 2.33763\n",
      "############################################\n",
      "117/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1125744, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.465335\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51136\tvalid_1's rmse: 2.28004\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's rmse: 2.63338\tvalid_1's rmse: 2.27141\n",
      "############################################\n",
      "118/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.138379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1236\n",
      "[LightGBM] [Info] Number of data points in the train set: 1132464, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.463509\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51113\tvalid_1's rmse: 2.38183\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's rmse: 2.64117\tvalid_1's rmse: 2.36357\n",
      "############################################\n",
      "119/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.139104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1236\n",
      "[LightGBM] [Info] Number of data points in the train set: 1142544, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.461545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.50402\tvalid_1's rmse: 2.31435\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's rmse: 2.64577\tvalid_1's rmse: 2.3082\n",
      "############################################\n",
      "120/120\n",
      "############################################\n",
      "NaN_train 0\n",
      "NaN_test 0\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1236\n",
      "[LightGBM] [Info] Number of data points in the train set: 1147584, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 8.460138\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.51079\tvalid_1's rmse: 2.31247\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's rmse: 2.69991\tvalid_1's rmse: 2.30307\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ls)):\n",
    "    \n",
    "    if i == 0:\n",
    "        print('############################################')\n",
    "        print(str(i+1) + '/' + str(len(ls)))\n",
    "        print('############################################')\n",
    "\n",
    "        s = ls[i]\n",
    "\n",
    "        train = whole[whole['date'] < s]\n",
    "        train = train.append(whole[whole['date'] == s][whole['hour'] == 0])\n",
    "        test = whole[whole['date'] == s][whole['predict'] == 1]\n",
    "        \n",
    "        nan_ids = train[train['bikes_available'].isnull()]['id'].to_list()\n",
    "        nan_ids[len(nan_ids):len(nan_ids)] = test[test['bikes_available'].isnull()]['id'].to_list()\n",
    "\n",
    "        for i in range(len(nan_ids)):\n",
    "            week_ago = whole[whole['id'] == nan_ids[i]]['date'] - timedelta(days=7)\n",
    "            week_ago = week_ago.values[0]\n",
    "\n",
    "            if (whole[whole['id'] == nan_ids[i]]['holiday'] == whole[whole['date'] == week_ago].iloc[0,9]).values[0]:\n",
    "                week_ago = week_ago\n",
    "            else:\n",
    "                week_ago = whole[whole['id'] == nan_ids[i]]['date'] - timedelta(days=14)\n",
    "                week_ago = week_ago.values[0]\n",
    "\n",
    "            station_id = whole[whole['id'] == nan_ids[i]]['station_id']\n",
    "            station_id = station_id.values[0]\n",
    "            hour = whole[whole['id'] == nan_ids[i]]['hour']\n",
    "            hour = hour.values[0]\n",
    "\n",
    "            whole.loc[(whole['id'] == nan_ids[i]), 'bikes_available'] = whole[(whole['date'] == week_ago) & (whole['hour'] == hour) & (whole['station_id'] == station_id)]['bikes_available'].values[0]\n",
    "\n",
    "        train = whole[whole['date'] < s]\n",
    "        #train = train.append(whole[whole['date'] == s][whole['hour'] == 0])\n",
    "        test = whole[whole['date'] == s][whole['predict'] == 1]\n",
    "\n",
    "        print('NaN_train ' + str(train['bikes_available'].isnull().sum()))\n",
    "        print('NaN_test ' + str(test['bikes_available'].isnull().sum()))\n",
    "\n",
    "        tss = TimeSeriesSplit(n_splits=2, test_size=744)\n",
    "\n",
    "        for i in range(70):\n",
    "            \n",
    "            if i == 0:\n",
    "                df = train[train['station_id'] == i]\n",
    "        \n",
    "                x = df.drop(['id', 'predict', 'date', 'events', 'bikes_available'], axis=1)\n",
    "                y = df['bikes_available'] \n",
    "        \n",
    "                for tr_idx, va_idx in tss.split(df):\n",
    "                    tr_x, va_x = x.iloc[tr_idx], x.iloc[va_idx]\n",
    "                    tr_y, va_y = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "        \n",
    "            elif i > 0:\n",
    "                df = train[train['station_id'] == i]\n",
    "        \n",
    "                x = df.drop(['id', 'predict', 'date', 'events', 'bikes_available'], axis=1)\n",
    "                y = df['bikes_available'] \n",
    "        \n",
    "                for tr_idx, va_idx in tss.split(df):\n",
    "                    tr_x_, va_x_ = x.iloc[tr_idx], x.iloc[va_idx]\n",
    "                    tr_y_, va_y_ = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "                \n",
    "                tr_x = pd.concat([tr_x,tr_x_])\n",
    "                va_x = pd.concat([va_x,va_x_])\n",
    "                tr_y = pd.concat([tr_y,tr_y_])\n",
    "                va_y = pd.concat([va_y,va_y_])\n",
    "        \n",
    "        \n",
    "\n",
    "        lgb_train = lgb.Dataset(tr_x,tr_y)\n",
    "        lgb_eval = lgb.Dataset(va_x,va_y)\n",
    "        \n",
    "        params = {'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'feature_pre_filter': False,\n",
    "                'lambda_l1': 3.0219157234596604e-06,\n",
    "                'lambda_l2': 2.6309832619595715e-05,\n",
    "                'num_leaves': 137,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 1.0,\n",
    "                'bagging_freq': 0,\n",
    "                'min_child_samples': 5,\n",
    "                'num_iterations': 1000,\n",
    "                'early_stopping_round': 100}\n",
    "                \n",
    "\n",
    "        model = lgb.train(params,lgb_train,valid_sets=[lgb_train,lgb_eval],\n",
    "                        verbose_eval=100,num_boost_round=10000,\n",
    "                        early_stopping_rounds=100)\n",
    "\n",
    "        test_ = test.drop(['id', 'predict', 'date', 'events', 'bikes_available',], axis=1)\n",
    "        prediction = model.predict(test_)\n",
    "        \n",
    "        test['bikes_available'] = prediction\n",
    "\n",
    "        sub = test[['id','bikes_available']]\n",
    "\n",
    "        ls_ = test['id'].tolist()\n",
    "\n",
    "        for i in ls_:\n",
    "            whole.loc[(whole['id'] == i), 'bikes_available'] = test.loc[(test['id'] == i), 'bikes_available'].values[0]\n",
    "        \n",
    "\n",
    "    elif i >= 1:\n",
    "        print('############################################')\n",
    "        print(str(i+1) + '/' + str(len(ls)))\n",
    "        print('############################################')\n",
    "\n",
    "        s = ls[i]\n",
    "\n",
    "        train = whole[whole['date'] < s]\n",
    "        train = train.append(whole[whole['date'] == s][whole['hour'] == 0])\n",
    "        test = whole[whole['date'] == s][whole['predict'] == 1]\n",
    "\n",
    "        nan_ids = train[train['bikes_available'].isnull()]['id'].to_list()\n",
    "        nan_ids[len(nan_ids):len(nan_ids)] = test[test['bikes_available'].isnull()]['id'].to_list()\n",
    "\n",
    "        for i in range(len(nan_ids)):\n",
    "            week_ago = whole[whole['id'] == nan_ids[i]]['date'] - timedelta(days=7)\n",
    "            week_ago = week_ago.values[0]\n",
    "\n",
    "            if (whole[whole['id'] == nan_ids[i]]['holiday'] == whole[whole['date'] == week_ago].iloc[0,9]).values[0]:\n",
    "                week_ago = week_ago\n",
    "            else:\n",
    "                week_ago = whole[whole['id'] == nan_ids[i]]['date'] - timedelta(days=14)\n",
    "                week_ago = week_ago.values[0]\n",
    "\n",
    "            station_id = whole[whole['id'] == nan_ids[i]]['station_id']\n",
    "            station_id = station_id.values[0]\n",
    "            hour = whole[whole['id'] == nan_ids[i]]['hour']\n",
    "            hour = hour.values[0]\n",
    "\n",
    "            whole.loc[(whole['id'] == nan_ids[i]), 'bikes_available'] = whole[(whole['date'] == week_ago) & (whole['hour'] == hour) & (whole['station_id'] == station_id)]['bikes_available'].values[0]\n",
    "\n",
    "        train = whole[whole['date'] < s]\n",
    "        #train = train.append(whole[whole['date'] == s][whole['hour'] == 0])\n",
    "        test = whole[whole['date'] == s][whole['predict'] == 1]\n",
    "\n",
    "        print('NaN_train ' + str(train['bikes_available'].isnull().sum()))\n",
    "        print('NaN_test ' + str(test['bikes_available'].isnull().sum()))\n",
    "        \n",
    "        tss = TimeSeriesSplit(n_splits=2, test_size=744)\n",
    "\n",
    "        for i in range(70):\n",
    "            \n",
    "            if i == 0:\n",
    "                df = train[train['station_id'] == i]\n",
    "        \n",
    "                x = df.drop(['id', 'predict', 'date', 'events', 'bikes_available'], axis=1)\n",
    "                y = df['bikes_available'] \n",
    "        \n",
    "                for tr_idx, va_idx in tss.split(df):\n",
    "                    tr_x, va_x = x.iloc[tr_idx], x.iloc[va_idx]\n",
    "                    tr_y, va_y = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "        \n",
    "            elif i > 0:\n",
    "                df = train[train['station_id'] == i]\n",
    "        \n",
    "                x = df.drop(['id', 'predict', 'date', 'events', 'bikes_available'], axis=1)\n",
    "                y = df['bikes_available'] \n",
    "        \n",
    "                for tr_idx, va_idx in tss.split(df):\n",
    "                    tr_x_, va_x_ = x.iloc[tr_idx], x.iloc[va_idx]\n",
    "                    tr_y_, va_y_ = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "                \n",
    "                tr_x = pd.concat([tr_x,tr_x_])\n",
    "                va_x = pd.concat([va_x,va_x_])\n",
    "                tr_y = pd.concat([tr_y,tr_y_])\n",
    "                va_y = pd.concat([va_y,va_y_])\n",
    "\n",
    "            \n",
    "                \n",
    "        lgb_train=lgb.Dataset(tr_x,tr_y)\n",
    "        lgb_eval=lgb.Dataset(va_x,va_y)\n",
    "\n",
    "        params = {'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'feature_pre_filter': False,\n",
    "                'lambda_l1': 3.0219157234596604e-06,\n",
    "                'lambda_l2': 2.6309832619595715e-05,\n",
    "                'num_leaves': 137,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 1.0,\n",
    "                'bagging_freq': 0,\n",
    "                'min_child_samples': 5,\n",
    "                'num_iterations': 1000,\n",
    "                'early_stopping_round': 100}\n",
    "\n",
    "        model=lgb.train(params,lgb_train,valid_sets=[lgb_train,lgb_eval],\n",
    "                        verbose_eval=100,num_boost_round=10000,\n",
    "                        early_stopping_rounds=100)\n",
    "\n",
    "        test_ = test.drop(['id', 'predict', 'date', 'events', 'bikes_available'], axis=1)\n",
    "        prediction = model.predict(test_)\n",
    "        \n",
    "        test['bikes_available'] = prediction\n",
    "        \n",
    "        sub_ = test[['id','bikes_available']]\n",
    "        sub = pd.concat([sub, sub_ ], ignore_index=True)\n",
    "\n",
    "        ls_ = test['id'].tolist()\n",
    "\n",
    "        for i in ls_:\n",
    "            whole.loc[(whole['id'] == i), 'bikes_available'] = test.loc[(test['id'] == i), 'bikes_available'].values[0]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量重要度を保管する dataframe を用意\n",
    "feature_importances = pd.DataFrame()\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "\n",
    "    tmp = pd.DataFrame()\n",
    "    tmp['feature'] = model.feature_name()\n",
    "    tmp['importance'] = model.feature_importance(importance_type='gain')\n",
    "    tmp['fold'] = fold\n",
    "\n",
    "    feature_importances = feature_importances.append(tmp)\n",
    "\n",
    "# 各特徴量で集約して、重要度の平均を算出。上位50個だけ抜き出す\n",
    "order = list(feature_importances.groupby(\"feature\")[\"importance\"].mean().sort_values(ascending=False).index)[:50]\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importances, order=order)\n",
    "plt.title('LGBM importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('sub_lightgbm.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a9a3f5c8c3076a5167ef2225a65d20e50e7e5b56ad4d066013b9a9bd86ee838"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('kaggle': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
